{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MuchLearningSuchWow - LSTM - WRMSSE Evaluation\n",
    "\n",
    "This notebook contains the code we used to create our WRMSSE evaluator, to score our predictions. The evaluator is based on the one found in [this discussion](https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from WRMSSEEvaluator import WRMSSEEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"input/m5-forecasting-accuracy/\"\n",
    "outputPath = \"output/\"\n",
    "submissionPath = \"submissions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv(inputPath + \"/sales_train_evaluation.csv\")\n",
    "df_calendar = pd.read_csv(inputPath + \"/calendar.csv\")\n",
    "df_prices = pd.read_csv(inputPath + \"/sell_prices.csv\")\n",
    "df_sample_submission = pd.read_csv(inputPath + \"/sample_submission.csv\")\n",
    "\n",
    "submission = pd.read_csv(submissionPath + \"/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_sales.iloc[:, :-28]\n",
    "df_valid = df_sales.iloc[:, -28:]\n",
    "del df_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3f213d752e4e75b61954ecd6272475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = WRMSSEEvaluator(df_train, df_valid, df_calendar, df_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission[\"order\"] = range(df_sample_submission.shape[0])\n",
    "preds_valid = submission\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRMSSE: 0.8506850770826887\n"
     ]
    }
   ],
   "source": [
    "groups, scores = evaluator.score(preds_valid)\n",
    "wrmsse_score = np.mean(scores)\n",
    "print(\"WRMSSE: \"+str(wrmsse_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
