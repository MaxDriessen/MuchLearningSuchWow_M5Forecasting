{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MuchLearningSuchWow - LSTM - Testing\n",
    "\n",
    "This notebook contains the code we used to test our LSTM network. The training code is based primarily on [this kernel](https://www.kaggle.com/bountyhunters/baseline-lstm-with-keras-0-7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import keras\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"input/m5-forecasting-accuracy/\"\n",
    "outputPath = \"output/\"\n",
    "modelPath = \"models/\"\n",
    "submissionPath = \"submissions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 14 # Number of previous days that will be used to predict the next day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputPath + \"/preprocessed_train_valid_data.pkl\", \"rb\") as f:\n",
    "    df_train_valid = pickle.load(f)\n",
    "with open(outputPath + \"/additional_features_testing.pkl\", \"rb\") as f:\n",
    "    additional_features_valid, additional_features_eval = pickle.load(f)\n",
    "with open(outputPath + \"/scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv(inputPath + \"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "model = keras.models.load_model(modelPath + \"/lstm_model_best\", custom_objects = {'root_mean_squared_error' : root_mean_squared_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, timesteps, input_data, scaler, nr_days_to_predict, additional_features):\n",
    "    # Scale and convert input data so that it can be fed into the model\n",
    "    inputs = scaler.transform(input_data)\n",
    "    X_test = np.array([inputs])\n",
    "    \n",
    "    # Predict sales for the next nr_days_to_predict days\n",
    "    predictions = []\n",
    "    for j in range(0, nr_days_to_predict):\n",
    "        predicted_sales = model.predict(X_test[:,-timesteps:,:].reshape(1, timesteps, 30490 + additional_features.shape[1]))\n",
    "        test_input = np.column_stack((np.array(predicted_sales), additional_features.iloc[[j]]))\n",
    "        test_input_expanded = np.expand_dims(test_input, 0)\n",
    "        X_test = np.append(X_test, test_input_expanded, axis = 1)\n",
    "        predicted_sales = scaler.inverse_transform(test_input)[:,0:30490]\n",
    "        predictions.append(predicted_sales)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid = test_model(model, timesteps, df_train_valid[-28-timesteps:-28], scaler, 28, additional_features_valid)\n",
    "predictions_eval = test_model(model, timesteps, df_train_valid[-timesteps:], scaler, 28, additional_features_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_valid = pd.DataFrame(data=np.array(predictions_valid).reshape(28,30490))\n",
    "submission_valid = submission_valid.T\n",
    "submission_eval = pd.DataFrame(data=np.array(predictions_eval).reshape(28,30490))\n",
    "submission_eval = submission_eval.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat((submission_valid, submission_eval), ignore_index=True)\n",
    "idColumn = df_sample_submission[[\"id\"]]\n",
    "submission[[\"id\"]] = idColumn  \n",
    "cols = list(submission.columns)\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "submission = submission[cols]\n",
    "colsdeneme = [\"id\"] + [f\"F{i}\" for i in range (1,29)]\n",
    "submission.columns = colsdeneme\n",
    "submission.to_csv(submissionPath + \"/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
