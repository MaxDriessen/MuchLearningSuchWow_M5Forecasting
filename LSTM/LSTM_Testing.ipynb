{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MuchLearningSuchWow - LSTM - Testing\n",
    "\n",
    "This notebook contains the code we used to test our LSTM network. The training code is based primarily on [this kernel](https://www.kaggle.com/bountyhunters/baseline-lstm-with-keras-0-7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import keras\n",
    "\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"input/m5-forecasting-accuracy/\"\n",
    "outputPath = \"output/\"\n",
    "modelPath = \"models/\"\n",
    "submissionPath = \"submissions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 14 # Number of previous days that will be used to predict the next day\n",
    "\n",
    "# Add rolling means?\n",
    "add_rollingMeans = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputPath + \"/preprocessed_train_valid_data.pkl\", \"rb\") as f:\n",
    "    df_train_valid = pickle.load(f)\n",
    "with open(outputPath + \"/additional_features_testing.pkl\", \"rb\") as f:\n",
    "    additional_features_valid, additional_features_eval = pickle.load(f)\n",
    "with open(outputPath + \"/scalers.pkl\", \"rb\") as f:\n",
    "    valid_scaler, eval_scaler = pickle.load(f)\n",
    "with open(outputPath + \"/item_data.pkl\", \"rb\") as f:\n",
    "    item_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv(inputPath + \"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "valid_model = keras.models.load_model(modelPath + \"/lstm_model_valid\", \n",
    "                                      custom_objects = {'root_mean_squared_error' : root_mean_squared_error})\n",
    "eval_model = keras.models.load_model(modelPath + \"/lstm_model_eval\", \n",
    "                                     custom_objects = {'root_mean_squared_error' : root_mean_squared_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rolling_means(test_data, predictions):\n",
    "    # Compute the next row of rolling means (this implementation works because input_data contains more than 7 days)\n",
    "    test_data = np.squeeze(test_data)\n",
    "    df_test_pred = pd.DataFrame(np.concatenate([test_data[:,:30490], predictions], axis = 0))\n",
    "    rolling_mean = pd.DataFrame(df_test_pred.rolling(7).mean())\n",
    "    rolling_mean = rolling_mean.fillna(0)\n",
    "\n",
    "    return rolling_mean[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, timesteps, input_data, scaler, nr_days_to_predict, additional_features):\n",
    "    # Scale and convert input data so that it can be fed into the model\n",
    "    inputs = scaler.transform(input_data)\n",
    "    X_test = np.array([inputs])\n",
    "    \n",
    "    # Predict sales for the next nr_days_to_predict days\n",
    "    predictions = []\n",
    "    for j in range(0, nr_days_to_predict):\n",
    "        feature_shape = 30490 + additional_features.shape[1]\n",
    "        if(add_rollingMeans): # If rolling means are present, feature_shape is 30490 + # additional features + 30490\n",
    "            feature_shape += 30490\n",
    "        model_input = np.append(np.expand_dims(item_data, 0), \n",
    "                                X_test[:,-timesteps:,:].reshape(1, timesteps, feature_shape), axis = 1)\n",
    "        predicted_sales = model.predict(model_input)\n",
    "        to_stack = [np.array(predicted_sales), additional_features.iloc[[j]]]\n",
    "        if(add_rollingMeans): # If rolling means are required, compute them and add them to model_output\n",
    "            rolling_means = compute_rolling_means(X_test, predicted_sales)\n",
    "            to_stack.append(rolling_means)\n",
    "        model_output = np.column_stack(tuple(to_stack))\n",
    "        model_output_expanded = np.expand_dims(model_output, 0)\n",
    "        X_test = np.append(X_test, model_output_expanded, axis = 1)\n",
    "        predicted_sales = scaler.inverse_transform(model_output)[:,0:30490]\n",
    "        predictions.append(predicted_sales)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid = test_model(valid_model, timesteps, df_train_valid[-28-timesteps:-28], \n",
    "                               valid_scaler, 28, additional_features_valid)\n",
    "predictions_eval = test_model(eval_model, timesteps, df_train_valid[-timesteps:], \n",
    "                              eval_scaler, 28, additional_features_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_valid = pd.DataFrame(data=np.array(predictions_valid).reshape(28,30490))\n",
    "submission_valid = submission_valid.T\n",
    "submission_eval = pd.DataFrame(data=np.array(predictions_eval).reshape(28,30490))\n",
    "submission_eval = submission_eval.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat((submission_valid, submission_eval), ignore_index=True)\n",
    "idColumn = df_sample_submission[[\"id\"]]\n",
    "submission[[\"id\"]] = idColumn  \n",
    "cols = list(submission.columns)\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "submission = submission[cols]\n",
    "colsdeneme = [\"id\"] + [f\"F{i}\" for i in range (1,29)]\n",
    "submission.columns = colsdeneme\n",
    "submission.to_csv(submissionPath + \"/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
