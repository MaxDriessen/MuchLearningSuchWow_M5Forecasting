{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MuchLearningSuchWow - LSTM - Training\n",
    "\n",
    "This notebook contains the code we used to define and train our LSTM network. The training code is based primarily on [this kernel](https://www.kaggle.com/bountyhunters/baseline-lstm-with-keras-0-7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = \"output/\"\n",
    "modelPath = \"models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 14 # Number of previous days that will be used to predict the next day\n",
    "startDay = 1000 # Number of days at start of data that will be ignored during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputPath + \"/preprocessed_train_data.pkl\", \"rb\") as f:\n",
    "    df_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(timesteps, 1913 - startDay):\n",
    "    X_train.append(df_train[i-timesteps:i])\n",
    "    y_train.append(df_train[i][0:30490]) # Only use first 30490 columns (sales) as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899, 14, 30491)\n",
      "(899, 30490)\n"
     ]
    }
   ],
   "source": [
    "# Convert data to np array to be able to feed it to the model\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1D convolution layer\n",
    "model.add(Conv1D(filters=32, kernel_size=7, strides=1, padding=\"causal\",activation=\"relu\",input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "# LSTM layers\n",
    "layer_1_units=150\n",
    "model.add(LSTM(units = layer_1_units, return_sequences = True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "layer_2_units=300\n",
    "model.add(LSTM(units = layer_2_units, return_sequences = True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "layer_3_units=400\n",
    "model.add(LSTM(units = layer_3_units))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units = 30490))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 14, 32)            6830016   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 14, 150)           109800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 14, 300)           541200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 400)               1121600   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30490)             12226490  \n",
      "=================================================================\n",
      "Total params: 20,829,106\n",
      "Trainable params: 20,829,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, modelPath + \"/model.png\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0221\n",
      "Epoch 2/50\n",
      "899/899 [==============================] - 32s 36ms/step - loss: 0.0202\n",
      "Epoch 3/50\n",
      "899/899 [==============================] - 32s 35ms/step - loss: 0.0197\n",
      "Epoch 4/50\n",
      "899/899 [==============================] - 32s 35ms/step - loss: 0.0193\n",
      "Epoch 5/50\n",
      "899/899 [==============================] - 32s 35ms/step - loss: 0.0189\n",
      "Epoch 6/50\n",
      "899/899 [==============================] - 32s 36ms/step - loss: 0.0186\n",
      "Epoch 7/50\n",
      "899/899 [==============================] - 32s 36ms/step - loss: 0.0184\n",
      "Epoch 8/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0182\n",
      "Epoch 9/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0180\n",
      "Epoch 10/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0179\n",
      "Epoch 11/50\n",
      "899/899 [==============================] - 34s 37ms/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "899/899 [==============================] - 34s 38ms/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "899/899 [==============================] - 32s 36ms/step - loss: 0.0176\n",
      "Epoch 15/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0178\n",
      "Epoch 16/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0177\n",
      "Epoch 17/50\n",
      "899/899 [==============================] - 34s 37ms/step - loss: 0.0175\n",
      "Epoch 18/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0173\n",
      "Epoch 19/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0173\n",
      "Epoch 20/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0172\n",
      "Epoch 21/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0172\n",
      "Epoch 22/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0170\n",
      "Epoch 23/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0170\n",
      "Epoch 24/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0169\n",
      "Epoch 25/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0168\n",
      "Epoch 26/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0168\n",
      "Epoch 27/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0170\n",
      "Epoch 28/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0168\n",
      "Epoch 29/50\n",
      "899/899 [==============================] - 32s 36ms/step - loss: 0.0169\n",
      "Epoch 30/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0166\n",
      "Epoch 31/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "899/899 [==============================] - 35s 39ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "899/899 [==============================] - 32s 36ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "899/899 [==============================] - 33s 36ms/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "899/899 [==============================] - 32s 36ms/step - loss: 0.0155\n",
      "Epoch 48/50\n",
      "899/899 [==============================] - 32s 36ms/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "899/899 [==============================] - 32s 36ms/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "899/899 [==============================] - 33s 37ms/step - loss: 0.0152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2693b606188>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer = Adam(learning_rate=0.001), loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the model to the training set\n",
    "nr_epochs = 50\n",
    "batch_size = 16\n",
    "model.fit(X_train, y_train, epochs = nr_epochs, batch_size = batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(modelPath + \"/lstm_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
